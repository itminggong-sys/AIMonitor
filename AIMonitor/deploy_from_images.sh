#!/bin/bash

# =============================================================================
# AI Monitor é•œåƒéƒ¨ç½²è„šæœ¬
# Version: 2.0.0
# Description: åˆ†ç¦»å¼éƒ¨ç½² - ç¬¬äºŒæ­¥ï¼šä»æœ¬åœ°é•œåƒéƒ¨ç½²æœåŠ¡
# Author: AI Assistant
# =============================================================================

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# è·å–å½“å‰æ—¶é—´æˆ³
get_timestamp() {
    date '+%Y-%m-%d %H:%M:%S'
}

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "[$(get_timestamp)] ${BLUE}â„¹ï¸  $1${NC}"
}

log_success() {
    echo -e "[$(get_timestamp)] ${GREEN}âœ… $1${NC}"
}

log_warning() {
    echo -e "[$(get_timestamp)] ${YELLOW}âš ï¸  $1${NC}"
}

log_error() {
    echo -e "[$(get_timestamp)] ${RED}âŒ $1${NC}"
}

# æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
show_welcome() {
    echo -e "${GREEN}==========================================${NC}"
    echo -e "${GREEN}    AI Monitor é•œåƒéƒ¨ç½²å·¥å…· v2.0${NC}"
    echo -e "${GREEN}==========================================${NC}"
    echo ""
    echo "æœ¬å·¥å…·å°†ä»é¢„æ„å»ºçš„Dockeré•œåƒéƒ¨ç½²AI Monitorç³»ç»Ÿ"
    echo "ç¡®ä¿å·²ç»è¿è¡Œäº† load_images.sh åŠ è½½æ‰€æœ‰é•œåƒ"
    echo ""
}

# æ£€æŸ¥Dockerç¯å¢ƒ
check_docker() {
    log_info "æ£€æŸ¥Dockerç¯å¢ƒ"
    
    if ! command -v docker &> /dev/null; then
        log_error "Docker æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker"
        exit 1
    fi
    
    if ! docker info &> /dev/null; then
        log_error "Docker æœåŠ¡æœªè¿è¡Œï¼Œè¯·å¯åŠ¨DockeræœåŠ¡"
        exit 1
    fi
    
    # æ£€æŸ¥docker-compose
    if ! command -v docker-compose &> /dev/null; then
        log_error "docker-compose æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…docker-compose"
        exit 1
    fi
    
    log_success "Dockerç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥å¿…éœ€çš„é•œåƒ
check_required_images() {
    log_info "æ£€æŸ¥å¿…éœ€çš„Dockeré•œåƒ"
    
    REQUIRED_IMAGES=(
        "ai-monitor-backend:latest"
        "ai-monitor-frontend:latest"
        "postgres:15-alpine"
        "redis:7-alpine"
        "prom/prometheus:latest"
        "docker.elastic.co/elasticsearch/elasticsearch:8.11.0"
    )
    
    MISSING_IMAGES=()
    
    for image in "${REQUIRED_IMAGES[@]}"; do
        if ! docker images --format "table {{.Repository}}:{{.Tag}}" | grep -q "^$image$"; then
            MISSING_IMAGES+=("$image")
        fi
    done
    
    if [ ${#MISSING_IMAGES[@]} -gt 0 ]; then
        log_error "ç¼ºå°‘ä»¥ä¸‹Dockeré•œåƒ:"
        for image in "${MISSING_IMAGES[@]}"; do
            echo "  - $image"
        done
        echo ""
        log_error "è¯·å…ˆè¿è¡Œ load_images.sh åŠ è½½æ‰€æœ‰é•œåƒ"
        exit 1
    fi
    
    log_success "æ‰€æœ‰å¿…éœ€é•œåƒæ£€æŸ¥é€šè¿‡"
}

# åˆ›å»ºå¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶
create_deployment_files() {
    log_info "åˆ›å»ºéƒ¨ç½²é…ç½®æ–‡ä»¶"
    
    # åˆ›å»ºconfigsç›®å½•
    mkdir -p configs
    
    # åˆ›å»ºconfig.yaml
    if [ ! -f "configs/config.yaml" ]; then
        cat > configs/config.yaml << 'EOF'
server:
  port: 8080
  mode: release

database:
  host: postgres
  port: 5432
  user: ai_monitor
  password: password
  dbname: ai_monitor
  sslmode: disable

redis:
  host: redis
  port: 6379
  password: ""
  db: 0

logging:
  level: info
  file: logs/app.log

metrics:
  enabled: true
  path: /metrics
EOF
    fi
    
    # åˆ›å»ºprometheusé…ç½®
    if [ ! -f "configs/prometheus.yml" ]; then
        cat > configs/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'ai-monitor'
    static_configs:
      - targets: ['aimonitor:8080']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
EOF
    fi
    
    # åˆ›å»ºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
    if [ ! -f "init.sql" ]; then
        cat > init.sql << 'EOF'
-- AI Monitor æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

-- åˆ›å»ºç”¨æˆ·è¡¨
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    password VARCHAR(255) NOT NULL,
    email VARCHAR(100),
    role VARCHAR(20) DEFAULT 'user',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºç›‘æ§æ•°æ®è¡¨
CREATE TABLE IF NOT EXISTS monitor_data (
    id SERIAL PRIMARY KEY,
    agent_id VARCHAR(100) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    metric_value DECIMAL(10,2),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    tags JSONB
);

-- åˆ›å»ºå‘Šè­¦è§„åˆ™è¡¨
CREATE TABLE IF NOT EXISTS alert_rules (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    condition TEXT NOT NULL,
    threshold DECIMAL(10,2),
    enabled BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºå‘Šè­¦å†å²è¡¨
CREATE TABLE IF NOT EXISTS alert_history (
    id SERIAL PRIMARY KEY,
    rule_id INTEGER REFERENCES alert_rules(id),
    message TEXT,
    level VARCHAR(20),
    triggered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP
);

-- æ’å…¥é»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·
INSERT INTO users (username, password, email, role) 
VALUES ('admin', '$2a$10$92IXUNpkjO0rOQ5byMi.Ye4oKoEa3Ro9llC/.og/at2.uheWG/igi', 'admin@example.com', 'admin')
ON CONFLICT (username) DO NOTHING;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_monitor_data_timestamp ON monitor_data(timestamp);
CREATE INDEX IF NOT EXISTS idx_monitor_data_agent_id ON monitor_data(agent_id);
CREATE INDEX IF NOT EXISTS idx_alert_history_triggered_at ON alert_history(triggered_at);
EOF
    fi
    
    # åˆ›å»ºRedisé…ç½®
    mkdir -p deploy
    if [ ! -f "deploy/redis.conf" ]; then
        cat > deploy/redis.conf << 'EOF'
# Redisé…ç½®æ–‡ä»¶
bind 0.0.0.0
port 6379
timeout 0
tcp-keepalive 300

# å†…å­˜ç®¡ç†
maxmemory 256mb
maxmemory-policy allkeys-lru

# æŒä¹…åŒ–
save 900 1
save 300 10
save 60 10000

# æ—¥å¿—
loglevel notice
logfile ""

# å®‰å…¨
# requirepass your_password_here
EOF
    fi
    
    log_success "éƒ¨ç½²é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºdocker-composeé…ç½®
create_docker_compose() {
    log_info "åˆ›å»ºdocker-composeé…ç½®æ–‡ä»¶"
    
    cat > docker-compose.production.yml << 'EOF'
services:
  postgres:
    image: postgres:15-alpine
    container_name: ai-monitor-postgres
    environment:
      POSTGRES_DB: ai_monitor
      POSTGRES_USER: ai_monitor
      POSTGRES_PASSWORD: password
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_monitor -d ai_monitor"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - ai-monitor-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    container_name: ai-monitor-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./deploy/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - ai-monitor-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  aimonitor:
    image: ai-monitor-backend:latest
    container_name: ai-monitor-backend
    ports:
      - "8080:8080"
    environment:
      - DB_HOST=postgres
      - REDIS_HOST=redis
      - GIN_MODE=release
    volumes:
      - ./configs:/app/configs
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - ai-monitor-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  frontend:
    image: ai-monitor-frontend:latest
    container_name: ai-monitor-frontend
    ports:
      - "3000:80"
    depends_on:
      aimonitor:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - ai-monitor-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  prometheus:
    image: prom/prometheus:latest
    container_name: ai-monitor-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./configs/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - ai-monitor-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: ai-monitor-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - ai-monitor-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  elasticsearch_data:
    driver: local

networks:
  ai-monitor-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
EOF
    
    log_success "docker-composeé…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åœæ­¢æ—§æœåŠ¡
stop_old_services() {
    log_info "åœæ­¢æ—§æœåŠ¡"
    
    # å°è¯•åœæ­¢å¯èƒ½å­˜åœ¨çš„æœåŠ¡
    docker-compose -f docker-compose.production.yml down --remove-orphans 2>/dev/null || true
    docker-compose down --remove-orphans 2>/dev/null || true
    
    # æ¸…ç†æ‚¬æŒ‚çš„å®¹å™¨
    docker container prune -f 2>/dev/null || true
    
    log_success "æ—§æœåŠ¡åœæ­¢å®Œæˆ"
}

# åˆ›å»ºå¿…è¦çš„ç›®å½•
create_directories() {
    log_info "åˆ›å»ºå¿…è¦çš„ç›®å½•"
    
    mkdir -p logs
    mkdir -p data
    
    # è®¾ç½®ç›®å½•æƒé™
    chmod 755 logs
    chmod 755 data
    
    log_success "ç›®å½•åˆ›å»ºå®Œæˆ"
}

# å¯åŠ¨æœåŠ¡
start_services() {
    log_info "å¯åŠ¨AI MonitoræœåŠ¡"
    
    # å¯åŠ¨æ‰€æœ‰æœåŠ¡
    docker-compose -f docker-compose.production.yml up -d
    
    if [ $? -eq 0 ]; then
        log_success "æœåŠ¡å¯åŠ¨å‘½ä»¤æ‰§è¡ŒæˆåŠŸ"
    else
        log_error "æœåŠ¡å¯åŠ¨å¤±è´¥"
        exit 1
    fi
}

# ç­‰å¾…æœåŠ¡å¯åŠ¨
wait_for_services() {
    log_info "ç­‰å¾…æœåŠ¡å®Œå…¨å¯åŠ¨"
    
    # ç­‰å¾…åŸºç¡€æœåŠ¡å¯åŠ¨
    sleep 30
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    log_info "æ£€æŸ¥æœåŠ¡çŠ¶æ€"
    docker-compose -f docker-compose.production.yml ps
    
    log_success "æœåŠ¡çŠ¶æ€æ£€æŸ¥å®Œæˆ"
}

# å¥åº·æ£€æŸ¥
health_check() {
    log_info "æ‰§è¡ŒæœåŠ¡å¥åº·æ£€æŸ¥"
    
    MAX_ATTEMPTS=15
    ATTEMPT=1
    
    # æ£€æŸ¥åç«¯æœåŠ¡
    while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
        log_info "å¥åº·æ£€æŸ¥å°è¯• $ATTEMPT/$MAX_ATTEMPTS"
        
        if curl -f -s http://localhost:8080/health > /dev/null 2>&1; then
            log_success "åç«¯æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
            break
        else
            if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                log_error "åç«¯æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
                log_info "æŸ¥çœ‹åç«¯æœåŠ¡æ—¥å¿—:"
                docker-compose -f docker-compose.production.yml logs --tail=50 aimonitor
                return 1
            fi
            log_warning "åç«¯æœåŠ¡å°šæœªå°±ç»ªï¼Œç­‰å¾…15ç§’åé‡è¯•..."
            sleep 15
            ATTEMPT=$((ATTEMPT + 1))
        fi
    done
    
    # æ£€æŸ¥å‰ç«¯æœåŠ¡
    if curl -f -s http://localhost:3000 > /dev/null 2>&1; then
        log_success "å‰ç«¯æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
    else
        log_warning "å‰ç«¯æœåŠ¡å¯èƒ½å°šæœªå®Œå…¨å°±ç»ª"
    fi
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if docker-compose -f docker-compose.production.yml exec -T postgres pg_isready -U ai_monitor -d ai_monitor > /dev/null 2>&1; then
        log_success "æ•°æ®åº“è¿æ¥æ£€æŸ¥é€šè¿‡"
    else
        log_warning "æ•°æ®åº“è¿æ¥æ£€æŸ¥å¤±è´¥"
    fi
    
    log_success "å¥åº·æ£€æŸ¥å®Œæˆ"
}

# æ˜¾ç¤ºéƒ¨ç½²ç»“æœ
show_deployment_result() {
    echo ""
    echo -e "${GREEN}ğŸ‰ AI Monitor éƒ¨ç½²å®Œæˆï¼${NC}"
    echo "=========================================="
    echo -e "${BLUE}ğŸ“‹ æœåŠ¡è®¿é—®åœ°å€:${NC}"
    
    # è·å–æœåŠ¡å™¨IP
    SERVER_IP=$(hostname -I | awk '{print $1}' 2>/dev/null || echo "localhost")
    
    echo "  å‰ç«¯ç•Œé¢: http://$SERVER_IP:3000"
    echo "  åç«¯API: http://$SERVER_IP:8080"
    echo "  APIæ–‡æ¡£: http://$SERVER_IP:8080/swagger/index.html"
    echo "  å¥åº·æ£€æŸ¥: http://$SERVER_IP:8080/health"
    echo "  Prometheus: http://$SERVER_IP:9090"
    echo "  Elasticsearch: http://$SERVER_IP:9200"
    echo ""
    echo -e "${YELLOW}ğŸ”§ ç®¡ç†å‘½ä»¤:${NC}"
    echo "  æŸ¥çœ‹æœåŠ¡çŠ¶æ€: docker-compose -f docker-compose.production.yml ps"
    echo "  æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—: docker-compose -f docker-compose.production.yml logs"
    echo "  æŸ¥çœ‹åç«¯æ—¥å¿—: docker-compose -f docker-compose.production.yml logs aimonitor"
    echo "  æŸ¥çœ‹å‰ç«¯æ—¥å¿—: docker-compose -f docker-compose.production.yml logs frontend"
    echo "  é‡å¯æœåŠ¡: docker-compose -f docker-compose.production.yml restart"
    echo "  åœæ­¢æœåŠ¡: docker-compose -f docker-compose.production.yml down"
    echo "  æ›´æ–°æœåŠ¡: docker-compose -f docker-compose.production.yml up -d"
    echo ""
    echo -e "${GREEN}ğŸ“Š é»˜è®¤ç™»å½•ä¿¡æ¯:${NC}"
    echo "  ç”¨æˆ·å: admin"
    echo "  å¯†ç : password"
    echo ""
    echo -e "${GREEN}âœ… éƒ¨ç½²æˆåŠŸï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ª${NC}"
    echo ""
}

# åˆ›å»ºç®¡ç†è„šæœ¬
create_management_scripts() {
    log_info "åˆ›å»ºç®¡ç†è„šæœ¬"
    
    # åˆ›å»ºæœåŠ¡ç®¡ç†è„šæœ¬
    cat > manage.sh << 'EOF'
#!/bin/bash

# AI Monitor æœåŠ¡ç®¡ç†è„šæœ¬

COMPOSE_FILE="docker-compose.production.yml"

case "$1" in
    start)
        echo "å¯åŠ¨AI MonitoræœåŠ¡..."
        docker-compose -f $COMPOSE_FILE up -d
        ;;
    stop)
        echo "åœæ­¢AI MonitoræœåŠ¡..."
        docker-compose -f $COMPOSE_FILE down
        ;;
    restart)
        echo "é‡å¯AI MonitoræœåŠ¡..."
        docker-compose -f $COMPOSE_FILE restart
        ;;
    status)
        echo "AI MonitoræœåŠ¡çŠ¶æ€:"
        docker-compose -f $COMPOSE_FILE ps
        ;;
    logs)
        if [ -n "$2" ]; then
            docker-compose -f $COMPOSE_FILE logs -f "$2"
        else
            docker-compose -f $COMPOSE_FILE logs -f
        fi
        ;;
    update)
        echo "æ›´æ–°AI MonitoræœåŠ¡..."
        docker-compose -f $COMPOSE_FILE pull
        docker-compose -f $COMPOSE_FILE up -d
        ;;
    backup)
        echo "å¤‡ä»½æ•°æ®åº“..."
        docker-compose -f $COMPOSE_FILE exec postgres pg_dump -U ai_monitor ai_monitor > "backup_$(date +%Y%m%d_%H%M%S).sql"
        echo "å¤‡ä»½å®Œæˆ"
        ;;
    *)
        echo "ç”¨æ³•: $0 {start|stop|restart|status|logs [service]|update|backup}"
        echo "ç¤ºä¾‹:"
        echo "  $0 start          # å¯åŠ¨æ‰€æœ‰æœåŠ¡"
        echo "  $0 stop           # åœæ­¢æ‰€æœ‰æœåŠ¡"
        echo "  $0 restart        # é‡å¯æ‰€æœ‰æœåŠ¡"
        echo "  $0 status         # æŸ¥çœ‹æœåŠ¡çŠ¶æ€"
        echo "  $0 logs           # æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—"
        echo "  $0 logs aimonitor # æŸ¥çœ‹åç«¯æ—¥å¿—"
        echo "  $0 update         # æ›´æ–°æœåŠ¡"
        echo "  $0 backup         # å¤‡ä»½æ•°æ®åº“"
        exit 1
        ;;
esac
EOF
    
    chmod +x manage.sh
    
    # åˆ›å»ºç›‘æ§è„šæœ¬
    cat > monitor.sh << 'EOF'
#!/bin/bash

# AI Monitor ç³»ç»Ÿç›‘æ§è„šæœ¬

echo "=== AI Monitor ç³»ç»ŸçŠ¶æ€ ==="
echo "æ—¶é—´: $(date)"
echo ""

echo "=== Docker æœåŠ¡çŠ¶æ€ ==="
docker-compose -f docker-compose.production.yml ps
echo ""

echo "=== ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ ==="
echo "CPUä½¿ç”¨ç‡:"
top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1
echo ""
echo "å†…å­˜ä½¿ç”¨æƒ…å†µ:"
free -h
echo ""
echo "ç£ç›˜ä½¿ç”¨æƒ…å†µ:"
df -h
echo ""

echo "=== Docker å®¹å™¨èµ„æºä½¿ç”¨ ==="
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}\t{{.BlockIO}}"
echo ""

echo "=== æœåŠ¡å¥åº·æ£€æŸ¥ ==="
echo -n "åç«¯æœåŠ¡: "
if curl -f -s http://localhost:8080/health > /dev/null 2>&1; then
    echo "âœ… æ­£å¸¸"
else
    echo "âŒ å¼‚å¸¸"
fi

echo -n "å‰ç«¯æœåŠ¡: "
if curl -f -s http://localhost:3000 > /dev/null 2>&1; then
    echo "âœ… æ­£å¸¸"
else
    echo "âŒ å¼‚å¸¸"
fi

echo -n "Prometheus: "
if curl -f -s http://localhost:9090 > /dev/null 2>&1; then
    echo "âœ… æ­£å¸¸"
else
    echo "âŒ å¼‚å¸¸"
fi

echo -n "Elasticsearch: "
if curl -f -s http://localhost:9200 > /dev/null 2>&1; then
    echo "âœ… æ­£å¸¸"
else
    echo "âŒ å¼‚å¸¸"
fi
EOF
    
    chmod +x monitor.sh
    
    log_success "ç®¡ç†è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    show_welcome
    check_docker
    check_required_images
    create_deployment_files
    create_docker_compose
    stop_old_services
    create_directories
    start_services
    wait_for_services
    health_check
    create_management_scripts
    show_deployment_result
}

# é”™è¯¯å¤„ç†
trap 'log_error "éƒ¨ç½²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°æ—¥å¿—ä¿¡æ¯"' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main